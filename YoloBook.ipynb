{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LQ9BDgtz7BC5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @markdown Name this new dataset:\n",
        "dataset = '' # @param {type:'string'}\n",
        "\n",
        "# @title ## STEP 1 : Dataset Parameters\n",
        "# @markdown Select the things you want your model to detect:\n",
        "# @markdown Animals:\n",
        "person = False # @param {type:'boolean'}\n",
        "cat = False # @param {type:'boolean'}\n",
        "dog = False # @param {type:'boolean'}\n",
        "horse = False # @param {type:'boolean'}\n",
        "cow = False # @param {type:'boolean'}\n",
        "elephant = False # @param {type:'boolean'}\n",
        "bear = False # @param {type:'boolean'}\n",
        "zebra = False # @param {type:'boolean'}\n",
        "giraffe = False # @param {type:'boolean'}\n",
        "# @markdown Vehicles:\n",
        "car = False # @param {type:'boolean'}\n",
        "truck = False # @param {type:'boolean'}\n",
        "bus = False # @param {type:'boolean'}\n",
        "boat = False # @param {type:'boolean'}\n",
        "motorcycle = False # @param {type:'boolean'}\n",
        "airplane = False # @param {type:'boolean'}\n",
        "potted_plant = False # @param {type:'boolean'}\n",
        "train = False # @param {type:'boolean'}\n",
        "# @markdown Things:\n",
        "toilet = False # @param {type:'boolean'}\n",
        "skateboard = False # @param {type:'boolean'}\n",
        "knife = False # @param {type:'boolean'}\n",
        "bicycle = False # @param {type:'boolean'}\n",
        "umbrella = False # @param {type:'boolean'}\n",
        "\n",
        "# @markdown Choose the maximum number of videos you want to download:\n",
        "# @markdown (some may have been taken off of YouTube, etc..)\n",
        "max_videos_to_download = 0 # @param {type:'integer'}\n",
        "\n",
        "# @markdown Enter percentage of data to use for train set:\n",
        "training_percent = 70 # @param {type: 'integer'}\n",
        "# @markdown What to do with the rest?\n",
        "half_half = False # @param ['Use it all for val set', 'Half val set, half test set'] {type: 'string'}\n",
        "\n",
        "# @markdown Shuffle videos before downloading?\n",
        "# @markdown (recommended unless you want a very unbalanced dataset)\n",
        "shuffle = True # @param {type:'bool'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8rqz7ttf9vCt"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 2 : Model Selection\n",
        "# @markdown Choose which size of YOLOv5 model to use:\n",
        "network_size = 'small' # @param ['small', 'medium', 'large', 'xl'] {type:'string'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "environment_setup"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 3 : Environment Setup\n",
        "# @markdown Choose your compute environment:\n",
        "use_colab = True # @param {type:'boolean'}\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if use_colab:\n",
        "    print(\"setting up google colab environment...\")\n",
        "    # Mount Google Drive\n",
        "    try:\n",
        "        from google.colab import drive, files\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"google drive mounted successfully\")\n",
        "        \n",
        "        # Set paths for Colab\n",
        "        data_base_path = '/content/drive/MyDrive/yolov5_data'\n",
        "        os.makedirs(data_base_path, exist_ok=True)\n",
        "        \n",
        "    except ImportError:\n",
        "        print(\"warning: not in colab environment but use_colab=True\")\n",
        "        data_base_path = '../data'\n",
        "else:\n",
        "    print(\"setting up local environment...\")\n",
        "    data_base_path = '../data'\n",
        "    \n",
        "    # Check if running locally\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"warning: in colab but use_colab=False, switching to colab mode\")\n",
        "        use_colab = True\n",
        "        data_base_path = '/content/drive/MyDrive/yolov5_data'\n",
        "    except ImportError:\n",
        "        print(\"local environment detected\")\n",
        "\n",
        "print(f\"data will be stored at: {data_base_path}\")\n",
        "print(f\"environment: {'colab' if use_colab else 'local'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validate_config"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 4 : Validate Configuration\n",
        "\n",
        "# Collect selected classes\n",
        "class_vars = {\n",
        "    'person': person, 'cat': cat, 'dog': dog, 'horse': horse, 'cow': cow,\n",
        "    'elephant': elephant, 'bear': bear, 'zebra': zebra, 'giraffe': giraffe,\n",
        "    'car': car, 'truck': truck, 'bus': bus, 'boat': boat, 'motorcycle': motorcycle,\n",
        "    'airplane': airplane, 'train': train, 'bicycle': bicycle, 'potted_plant': potted_plant,\n",
        "    'toilet': toilet, 'skateboard': skateboard, 'knife': knife, 'umbrella': umbrella\n",
        "}\n",
        "\n",
        "selected_classes = [name for name, selected in class_vars.items() if selected]\n",
        "\n",
        "# Validation\n",
        "if not dataset.strip():\n",
        "    print(\"error: please provide a dataset name\")\n",
        "elif not selected_classes:\n",
        "    print(\"error: please select at least one object class\")\n",
        "elif max_videos_to_download <= 0:\n",
        "    print(\"error: please set max_videos_to_download to a positive number\")\n",
        "else:\n",
        "    print(\"configuration validated successfully\")\n",
        "    print(f\"\\ndataset: {dataset}\")\n",
        "    print(f\"classes: {', '.join(selected_classes)} ({len(selected_classes)} total)\")\n",
        "    print(f\"max videos: {max_videos_to_download}\")\n",
        "    print(f\"training %: {training_percent}%\")\n",
        "    print(f\"model size: {network_size}\")\n",
        "    print(f\"environment: {'colab' if use_colab else 'local'}\")\n",
        "    print(f\"\\nready to proceed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_dataset"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 5 : Create Dataset\n",
        "# @markdown This modifies and runs your process-data.py script\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# COCO class ID mapping for YouTube-BB\n",
        "YTBB_CLASS_MAPPING = {\n",
        "    'person': 1, 'bicycle': 2, 'car': 3, 'motorcycle': 4, 'airplane': 5,\n",
        "    'bus': 6, 'train': 7, 'truck': 8, 'boat': 9, 'skateboard': 37,\n",
        "    'cat': 17, 'dog': 18, 'horse': 19, 'cow': 21, 'elephant': 22,\n",
        "    'bear': 23, 'zebra': 24, 'giraffe': 25, 'potted_plant': 64,\n",
        "    'toilet': 70, 'knife': 49, 'umbrella': 28\n",
        "}\n",
        "\n",
        "def create_class_remapping(selected_classes):\n",
        "    ytbb_ids = [YTBB_CLASS_MAPPING[cls] for cls in selected_classes]\n",
        "    return {ytbb_id: idx for idx, ytbb_id in enumerate(ytbb_ids)}\n",
        "\n",
        "def create_yaml_config(dataset_name, selected_classes):\n",
        "    # Adjust paths based on environment\n",
        "    if use_colab:\n",
        "        data_path = f\"{data_base_path}/processed/{dataset_name}/data/\"\n",
        "    else:\n",
        "        data_path = f\"../../data/processed/{dataset_name}/data/\"\n",
        "    \n",
        "    yaml_content = f\"\"\"# -- written by cwa --\n",
        "\n",
        "#relative paths (from train.py)\n",
        "path: {data_path}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "# # of classes\n",
        "nc: {len(selected_classes)}\n",
        "\n",
        "# class names\n",
        "names: {selected_classes}\n",
        "\"\"\"\n",
        "    \n",
        "    yaml_path = f\"yolov5/dataset-{dataset_name}.yaml\"\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "    return yaml_path\n",
        "\n",
        "def modify_process_script():\n",
        "    # Read original script\n",
        "    with open('src/utility/process-data.py', 'r') as f:\n",
        "        script = f.read()\n",
        "    \n",
        "    # Calculate ratios\n",
        "    train_ratio = training_percent / 100.0\n",
        "    remaining = 1.0 - train_ratio\n",
        "    if half_half == 'Half val set, half test set':\n",
        "        val_ratio = remaining / 2.0\n",
        "        test_ratio = remaining / 2.0\n",
        "    else:\n",
        "        val_ratio = remaining\n",
        "        test_ratio = 0.0\n",
        "    \n",
        "    class_remapping = create_class_remapping(selected_classes)\n",
        "    \n",
        "    # Adjust data paths for environment\n",
        "    if use_colab:\n",
        "        raw_data_path = f\"{data_base_path}/raw/\"\n",
        "        processed_data_path = f\"{data_base_path}/processed/\"\n",
        "    else:\n",
        "        raw_data_path = \"../../data/raw/\"\n",
        "        processed_data_path = \"../../data/processed/\"\n",
        "    \n",
        "    # Replace parameters\n",
        "    replacements = {\n",
        "        \"dataset = 'extra'\": f\"dataset = '{dataset}'\",\n",
        "        \"classes = ['dog']\": f\"classes = {selected_classes}\",\n",
        "        \"max_videos_to_download = 50\": f\"max_videos_to_download = {max_videos_to_download}\",\n",
        "        \"class_remapping = {19: 0}\": f\"class_remapping = {class_remapping}\",\n",
        "        \"train_ratio = 0.68\": f\"train_ratio = {train_ratio}\",\n",
        "        \"val_ratio = 0.16\": f\"val_ratio = {val_ratio}\",\n",
        "        \"test_ratio = 0.16\": f\"test_ratio = {test_ratio}\",\n",
        "        \"shuffle = True\": f\"shuffle = {shuffle}\",\n",
        "        \"'../../data/raw/'\": f\"'{raw_data_path}'\",\n",
        "        \"'../../data/processed/'\": f\"'{processed_data_path}'\"\n",
        "    }\n",
        "    \n",
        "    for old, new in replacements.items():\n",
        "        script = script.replace(old, new)\n",
        "    \n",
        "    # Save modified script\n",
        "    with open('process_data_notebook.py', 'w') as f:\n",
        "        f.write(script)\n",
        "\n",
        "# Create YAML config\n",
        "yaml_path = create_yaml_config(dataset, selected_classes)\n",
        "print(f\"created yaml config: {yaml_path}\")\n",
        "\n",
        "# Modify processing script\n",
        "modify_process_script()\n",
        "print(f\"created modified processing script: process_data_notebook.py\")\n",
        "\n",
        "print(f\"\\nready to run data processing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_processing"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 6 : Run Data Processing\n",
        "# @markdown this will take several hours\n",
        "\n",
        "start_processing = False # @param {type:'boolean'}\n",
        "\n",
        "if start_processing:\n",
        "    print(\"starting data processing...\")\n",
        "    print(\"this will download videos, extract frames, and create annotations\")\n",
        "    print(\"progress will be shown below\\n\")\n",
        "    \n",
        "    # Make sure data directories exist\n",
        "    raw_dir = f\"{data_base_path}/raw\"\n",
        "    processed_dir = f\"{data_base_path}/processed\"\n",
        "    os.makedirs(raw_dir, exist_ok=True)\n",
        "    os.makedirs(processed_dir, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(['python', 'process_data_notebook.py'], \n",
        "                              capture_output=False, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"\\ndata processing completed successfully\")\n",
        "        else:\n",
        "            print(f\"\\ndata processing failed with return code: {result.returncode}\")\n",
        "    except Exception as e:\n",
        "        print(f\"error: {e}\")\n",
        "else:\n",
        "    print(\"set 'start_processing' to True to begin data processing\")\n",
        "    raw_path = f\"{data_base_path}/raw\" if use_colab else \"../../data/raw/\"\n",
        "    print(f\"make sure you have youtube-bb csv files in {raw_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_training"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 7 : Train Model\n",
        "\n",
        "# @markdown training parameters:\n",
        "epochs = 100 # @param {type:'integer'}\n",
        "batch_size = 16 # @param [8, 16, 32, 64]\n",
        "start_training = False # @param {type:'boolean'}\n",
        "\n",
        "if start_training:\n",
        "    # Get model name\n",
        "    model_map = {'small': 'yolov5s', 'medium': 'yolov5m', 'large': 'yolov5l', 'xl': 'yolov5x'}\n",
        "    model_name = model_map.get(network_size, 'yolov5s')\n",
        "    \n",
        "    print(f\"starting training with {model_name}...\")\n",
        "    \n",
        "    # Change to yolov5 directory\n",
        "    original_dir = os.getcwd()\n",
        "    os.chdir('yolov5')\n",
        "    \n",
        "    # Training command\n",
        "    cmd = [\n",
        "        'python', 'train.py',\n",
        "        '--data', f'dataset-{dataset}.yaml',\n",
        "        '--weights', f'{model_name}.pt',\n",
        "        '--epochs', str(epochs),\n",
        "        '--batch-size', str(batch_size),\n",
        "        '--name', f'{dataset}_training'\n",
        "    ]\n",
        "    \n",
        "    try:\n",
        "        subprocess.run(cmd, check=True)\n",
        "        print(\"\\ntraining completed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"training failed: {e}\")\n",
        "    finally:\n",
        "        os.chdir(original_dir)\n",
        "else:\n",
        "    print(\"set 'start_training' to True to begin training\")\n",
        "    print(f\"will train {network_size} model for {epochs} epochs with batch size {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visual_check"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 8 : Visual Inspection\n",
        "# @markdown use your existing visual-check.py utility\n",
        "\n",
        "run_visual_check = False # @param {type:'boolean'}\n",
        "subset = \"train\" # @param [\"train\", \"val\", \"test\"]\n",
        "\n",
        "if run_visual_check:\n",
        "    # Modify and run your visual-check.py\n",
        "    with open('src/utility/visual-check.py', 'r') as f:\n",
        "        script = f.read()\n",
        "    \n",
        "    # Replace parameters\n",
        "    script = script.replace(\"dataset = 'ytbb_cat'\", f\"dataset = '{dataset}'\")\n",
        "    script = script.replace(\"subset = 'train'\", f\"subset = '{subset}'\")\n",
        "    \n",
        "    # Adjust paths for environment\n",
        "    if use_colab:\n",
        "        old_path = \"'../../data/processed/'\"\n",
        "        new_path = f\"'{data_base_path}/processed/'\"\n",
        "        script = script.replace(old_path, new_path)\n",
        "    \n",
        "    # Execute\n",
        "    exec(script)\n",
        "else:\n",
        "    print(\"set 'run_visual_check' to True to inspect your dataset\")\n",
        "    print(\"this will show a random image with bounding box overlays\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_model"
      },
      "outputs": [],
      "source": [
        "# @title ## STEP 9 : Test Your Model\n",
        "# @markdown upload an image or video to test your trained model\n",
        "\n",
        "test_type = \"image\" # @param [\"image\", \"video\"]\n",
        "run_detection = False # @param {type:'boolean'}\n",
        "\n",
        "if run_detection:\n",
        "    model_path = f\"yolov5/runs/train/{dataset}_training/weights/best.pt\"\n",
        "    \n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"running detection on {test_type}...\")\n",
        "        \n",
        "        # Upload file based on environment\n",
        "        if use_colab:\n",
        "            from google.colab import files\n",
        "            print(f\"please upload your {test_type} file:\")\n",
        "            uploaded = files.upload()\n",
        "            \n",
        "            if uploaded:\n",
        "                filename = list(uploaded.keys())[0]\n",
        "                print(f\"uploaded: {filename}\")\n",
        "            else:\n",
        "                print(\"no file uploaded\")\n",
        "                filename = None\n",
        "        else:\n",
        "            # For local, user needs to provide path\n",
        "            import tkinter as tk\n",
        "            from tkinter import filedialog\n",
        "            \n",
        "            root = tk.Tk()\n",
        "            root.withdraw()\n",
        "            \n",
        "            if test_type == \"image\":\n",
        "                filetypes = [(\"Image files\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
        "            else:\n",
        "                filetypes = [(\"Video files\", \"*.mp4 *.avi *.mov *.mkv\")]\n",
        "                \n",
        "            filename = filedialog.askopenfilename(filetypes=filetypes)\n",
        "            \n",
        "            if filename:\n",
        "                print(f\"selected: {filename}\")\n",
        "            else:\n",
        "                print(\"no file selected\")\n",
        "        \n",
        "        if filename:\n",
        "            # Change to yolov5 directory\n",
        "            original_dir = os.getcwd()\n",
        "            os.chdir('yolov5')\n",
        "            \n",
        "            # Detection command\n",
        "            output_name = f'{dataset}_detection_{test_type}'\n",
        "            cmd = [\n",
        "                'python', 'detect.py',\n",
        "                '--weights', f'runs/train/{dataset}_training/weights/best.pt',\n",
        "                '--source', f'../{filename}',\n",
        "                '--name', output_name,\n",
        "                '--save-txt',\n",
        "                '--save-conf'\n",
        "            ]\n",
        "            \n",
        "            try:\n",
        "                subprocess.run(cmd, check=True)\n",
        "                output_dir = f\"runs/detect/{output_name}\"\n",
        "                print(f\"\\ndetection complete! check {output_dir}/\")\n",
        "                \n",
        "                # For Colab, provide download link\n",
        "                if use_colab:\n",
        "                    import glob\n",
        "                    result_files = glob.glob(f\"{output_dir}/*\")\n",
        "                    if result_files:\n",
        "                        print(\"\\ndownloading result files...\")\n",
        "                        for file_path in result_files:\n",
        "                            if os.path.isfile(file_path):\n",
        "                                files.download(file_path)\n",
        "                        \n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"detection failed: {e}\")\n",
        "            finally:\n",
        "                os.chdir(original_dir)\n",
        "                \n",
        "    else:\n",
        "        print(f\"model not found: {model_path}\")\n",
        "        print(\"please complete training first\")\n",
        "else:\n",
        "    print(\"set 'run_detection' to True to test your model\")\n",
        "    print(f\"will run inference on uploaded {test_type}\")\n",
        "    print(f\"model location: yolov5/runs/train/{dataset}_training/weights/best.pt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
